{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script makes smoothed EdU genomic profiles for replicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# useful imports\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from scipy.signal import convolve\n",
    "import peakutils\n",
    "\n",
    "\n",
    "# useful global variables\n",
    "# get oridb files to get locations of ars's\n",
    "oriDB_df = pd.read_csv('oriDB_confirmed_ARSs.bed',  \n",
    "                 names=['chromosome','start','stop','ars_name'], \n",
    "                 delim_whitespace=True, \n",
    "                 skiprows=2)\n",
    "\n",
    "chrX_list = ['chr1','chr2','chr3','chr4','chr5','chr6','chr7',\n",
    "                 'chr8','chr9','chr10','chr11','chr12','chr13','chr14','chr15','chr16']\n",
    "\n",
    "def get_smooth_reads(bed_file_name = 'orc_chip_sb13/chip_sb13_WT.txt',return_ars_location_dicts=False, smoothing_window_size = 300):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    This function takes reads aligned to a genome and returns\n",
    "    smoothed reads. \n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    \n",
    "    bed_file_name (str): name of file containing reads\n",
    "                        in the format: 'chromosome','start','stop','reads'\n",
    "    \n",
    "    smoothing_window_size (int): integer specifying width of smoothing window\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(bed_file_name,\n",
    "                     names=['chromosome','start','stop','reads'], \n",
    "                     delim_whitespace=True, \n",
    "                     skiprows=0)\n",
    "\n",
    "    \n",
    "    df = df.loc[df['chromosome']!='ref|NC_001224|'].copy()\n",
    "    \n",
    "    # lists to contain ars names and widths\n",
    "    ars_names_total = []\n",
    "    ars_widths_total = []\n",
    "    ars_heights_total = []\n",
    "    \n",
    "    # list for translating chromosome names from ref|NC_####| \n",
    "    # convention to chr#. This is done to increase readability\n",
    "    chrom_we_want_list=['ref|NC_001133|', 'ref|NC_001134|', 'ref|NC_001135|', 'ref|NC_001136|', 'ref|NC_001137|', 'ref|NC_001138|',\n",
    "    'ref|NC_001139|', 'ref|NC_001140|', 'ref|NC_001141|', 'ref|NC_001142|', 'ref|NC_001143|', 'ref|NC_001144|',\n",
    "    'ref|NC_001145|', 'ref|NC_001146|', 'ref|NC_001147|','ref|NC_001148|']\n",
    "\n",
    "    kb = 1E3\n",
    "\n",
    "    # dictionaries which can be used for plotting each chromosome profile\n",
    "    # outside of this loop\n",
    "    smooth_reads_dict = {}\n",
    "    smooth_reads_xs_dict = {}\n",
    "    ars_names_dict = {}\n",
    "    ars_heights_dict = {}\n",
    "    ars_heights_xs_dict = {}\n",
    "    ars_widths_dict = {}\n",
    "    ars_widths_xs_dict = {}\n",
    "    peak_locations_dict = {}\n",
    "\n",
    "    ### start loop here\n",
    "\n",
    "    for chromosome_index in range(len(chrX_list)):\n",
    "    #for chromosome_index in range(1):\n",
    "\n",
    "        chrX_indices = oriDB_df['chromosome']==chrX_list[chromosome_index]    # loop index should go here\n",
    "        chrom_we_want = chrom_we_want_list[chromosome_index]\n",
    "\n",
    "\n",
    "        chr2_locations =(oriDB_df[chrX_indices]['start']/kb+oriDB_df[chrX_indices]['stop']/kb)/2.0\n",
    "        chr2_names = oriDB_df[chrX_indices]['ars_name']\n",
    "\n",
    "        # Extract values for current chromosome \n",
    "        indices = df.loc[:,'chromosome']==chrom_we_want\n",
    "        chr2_df = df.loc[indices,:]\n",
    "\n",
    "        # Compute read length\n",
    "        read_length = df.loc[0,'stop'] - df.loc[0,'start'] + 1\n",
    "\n",
    "        # Extract vectors of starts, stops, and number of reads\n",
    "        starts = chr2_df.loc[:,'start'].values\n",
    "        stops = chr2_df.loc[:,'stop'].values\n",
    "        num_reads = chr2_df.loc[:,'reads'].astype(float).values\n",
    "\n",
    "        ### smoothing\n",
    "\n",
    "        # Create a \"kernel\" with which to smooth the data\n",
    "        # from experience, 6 kb is a nice window size\n",
    "        #window_bp = 300\n",
    "        window_bp = smoothing_window_size\n",
    "        read_length = 51\n",
    "        window_size = window_bp//read_length\n",
    "        # Create a window kernel so that all elements sum to 1\n",
    "        window = np.ones(window_size)/window_size\n",
    "\n",
    "        # Smooth the data by convolving (not convoluting!) the window with the read counts\n",
    "        smooth_reads = convolve(num_reads,window,'same')\n",
    "        # recording for plotting later (1)\n",
    "        smooth_reads_dict[chrX_list[chromosome_index]] = smooth_reads\n",
    "\n",
    "        ### get peaks\n",
    "        #max_indices = peakutils.indexes(smooth_reads, thres=0.05, min_dist=100)\n",
    "        max_indices = peakutils.indexes(smooth_reads, thres=0.2, min_dist=400)\n",
    "\n",
    "        ### isolate peaks\n",
    "\n",
    "        # this snippet could be vectorized...\n",
    "\n",
    "        listbwd = []\n",
    "        listfwd = []\n",
    "        yMax = []\n",
    "\n",
    "        for i in range(len(max_indices)):\n",
    "\n",
    "            yMax.append(smooth_reads[max_indices[i]])\n",
    "            indexOfPeakFwd = max_indices[i]\n",
    "            indexOfPeakBwd = max_indices[i]\n",
    "\n",
    "            while smooth_reads[indexOfPeakFwd] > yMax[i]/2.0:\n",
    "\n",
    "                if (indexOfPeakFwd+1) == len(starts):\n",
    "                    break\n",
    "                indexOfPeakFwd+=1\n",
    "\n",
    "            while smooth_reads[indexOfPeakBwd] > yMax[i]/2.0:\n",
    "\n",
    "                if (indexOfPeakBwd-1) <= 0:\n",
    "                    break\n",
    "                indexOfPeakBwd-=1\n",
    "\n",
    "            listbwd.append(indexOfPeakBwd)\n",
    "            listfwd.append(indexOfPeakFwd)\n",
    "\n",
    "        chr2_locations =(oriDB_df[chrX_indices]['start']/kb+oriDB_df[chrX_indices]['stop']/kb)/2.0 \n",
    "\n",
    "        ###  identify which peaks are ARS\n",
    "        ars_locations = chr2_locations.values.ravel()\n",
    "        peak_locations = starts[max_indices]/kb\n",
    "        \n",
    "        peak_locations_per_chromosome_list = []\n",
    "        for peak_index in range(len(max_indices)):\n",
    "            peak_locations_per_chromosome_list.append((starts[max_indices[peak_index]]+stops[max_indices[peak_index]])/(2))\n",
    "            \n",
    "        peak_locations_dict[chrX_list[chromosome_index]] = peak_locations_per_chromosome_list                    \n",
    "        \n",
    "        \n",
    "        ### get indices of clean ARS-Peaks combos\n",
    "\n",
    "        clean_peak_indices = []\n",
    "\n",
    "        # get index of closest numer\n",
    "        def closest(list, Number):\n",
    "            aux = []\n",
    "            for valor in list:\n",
    "                aux.append(abs(Number-valor))\n",
    "\n",
    "            return aux.index(min(aux))\n",
    "\n",
    "        for ipeak in range(len(peak_locations)):\n",
    "            #print(closest(ars_locations,peak_locations[ipeak]))\n",
    "            clean_peak_indices.append(closest(ars_locations,peak_locations[ipeak]))\n",
    "\n",
    "\n",
    "        ### record all ars heights\n",
    "        x = 0.5*(starts+stops)/kb\n",
    "        L = max(x)\n",
    "        # recording for plotting later (2)\n",
    "        smooth_reads_xs_dict[chrX_list[chromosome_index]] = x\n",
    "\n",
    "        # index array of where ars's are locations\n",
    "        indices_of_ars_locations = [] \n",
    "\n",
    "        # get index of closest numer\n",
    "        def closest(list, Number):\n",
    "            aux = []\n",
    "            for valor in list:\n",
    "                aux.append(abs(Number-valor))\n",
    "\n",
    "            return aux.index(min(aux))\n",
    "\n",
    "        for ith_ars_location in range(len(ars_locations)):    \n",
    "            indices_of_ars_locations.append(closest(x,ars_locations[ith_ars_location]))\n",
    "\n",
    "        # the heights of ars according to the smoothed profile    \n",
    "        #smooth_reads[indices_of_ars_locations] \n",
    "\n",
    "        for append_index in range(len(chr2_names.tolist())):\n",
    "            # record heights and names of the ars for the current chromosome\n",
    "            ars_names_total.append(chr2_names.tolist()[append_index])\n",
    "            ars_heights_total.append(smooth_reads[indices_of_ars_locations].tolist()[append_index])\n",
    "\n",
    "        ars_names_dict[chrX_list[chromosome_index]] = chr2_names.tolist()\n",
    "        ars_heights_dict[chrX_list[chromosome_index]] = smooth_reads[indices_of_ars_locations].tolist()\n",
    "        ars_heights_xs_dict[chrX_list[chromosome_index]] = ars_locations\n",
    "\n",
    "    ### store height results\n",
    "\n",
    "    # append the following three in a dataframe\n",
    "    #ars_locations    \n",
    "    #smooth_reads[indices_of_ars_locations]\n",
    "    # contains ars names\n",
    "    #chr2_names\n",
    "\n",
    "    # put everything in a dataframe\n",
    "    ars_height_df = pd.DataFrame(\n",
    "        {'ARS': ars_names_total,\n",
    "         'Heights': ars_heights_total\n",
    "        })\n",
    "\n",
    "    # Read Genome wide confirmed ARSs (Nieduszynski et. al.)\n",
    "\n",
    "    ars_location_table_raw = pd.read_csv('table_S1_Clean.csv',  \n",
    "                     names=['paper_name','name','chromosome','position','A_element',\n",
    "                            'Strand','Species Avail','Cons-Species','Cons-Score','Score-Mast',\n",
    "                            '5-Prime','3-Prime','ARS-activity','assay data'\n",
    "                           ], \n",
    "                     sep=',', \n",
    "                     skiprows=0)\n",
    "\n",
    "    # Change Conrad Supplement Table to ORIdb format to re-use code from before\n",
    "    ars_location_table_raw['chromosome'] = 'chr' + ars_location_table_raw['chromosome'].astype(str)\n",
    "    ars_location_table_raw['name'] = 'ARS' + ars_location_table_raw['name'].astype(str)\n",
    "    \n",
    "    Nieduszynski_df = pd.DataFrame(\n",
    "                                  {'chromosome':ars_location_table_raw['chromosome'].tolist(),\n",
    "                                  'position':ars_location_table_raw['position'].tolist(),\n",
    "                                  'name':ars_location_table_raw['name'].tolist(),\n",
    "                                  'sequence':ars_location_table_raw['A_element'].tolist(), \n",
    "                                  'strand':ars_location_table_raw['Strand'].tolist()\n",
    "                                  }\n",
    "                                  )\n",
    "\n",
    "\n",
    "    # to match the annotated ARS position with the nearest position of the smoothed_read xs\n",
    "    def find_nearest(array, value):\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        #return array[idx],idx\n",
    "        return idx\n",
    "\n",
    "\n",
    "    heights_at_conrad_ars_location_dict = {}\n",
    "\n",
    "\n",
    "    for current_chromosome in chrX_list:\n",
    "        #print(current_chromosome)\n",
    "\n",
    "        ars_names_list_conrad = Nieduszynski_df.loc[Nieduszynski_df['chromosome'] == current_chromosome]['name'].tolist()\n",
    "        ars_position_list_conrad = Nieduszynski_df.loc[Nieduszynski_df['chromosome'] == current_chromosome]['position'].tolist()\n",
    "\n",
    "        heights_at_conrad_ars_location = []\n",
    "\n",
    "        #smooth_reads_xs_dict\n",
    "        for ars_pos_index in range(len(ars_position_list_conrad)):\n",
    "            #ars_conrad_height_index = find_nearest(xs, ars_position_list_conrad[ars_pos_index]/kb)\n",
    "            ars_conrad_height_index = find_nearest(smooth_reads_xs_dict[current_chromosome], ars_position_list_conrad[ars_pos_index]/kb)\n",
    "            #print(smooth_reads_dict[chromosome_to_plot][ars_conrad_height_index])\n",
    "            heights_at_conrad_ars_location.append(smooth_reads_dict[current_chromosome][ars_conrad_height_index])\n",
    "\n",
    "        heights_at_conrad_ars_location_dict[current_chromosome] = heights_at_conrad_ars_location\n",
    "    \n",
    "    if(return_ars_location_dicts==False):\n",
    "        return smooth_reads_dict,smooth_reads_xs_dict, Nieduszynski_df, peak_locations_dict\n",
    "    else:\n",
    "        return smooth_reads_dict,smooth_reads_xs_dict, Nieduszynski_df, heights_at_conrad_ars_location_dict\n",
    "\n",
    "\n",
    "# normalizaton using 99.5 percentile across genome\n",
    "def percentile_across_genome(input_dict):\n",
    "    \n",
    "    # take entire genome dict values and put them in this list\n",
    "    concatenated_list = []\n",
    "    \n",
    "    for dict_index in range(len(input_dict.values())):\n",
    "        for array_index in range(len(input_dict.values()[dict_index])):\n",
    "            concatenated_list.append(input_dict.values()[dict_index][array_index])\n",
    "            \n",
    "    #return 99.5 percentile value which to normalize with\n",
    "    return np.percentile(concatenated_list,99.5)\n",
    "\n",
    "\n",
    "\n",
    "# further useful global variables\n",
    "lightblue = [0, .5, 1]\n",
    "orange = [1,0.5,0]\n",
    "\n",
    "figure_size = [28,7]\n",
    "label_size = 20\n",
    "title_size = 20\n",
    "kb=1E3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load EdU replicate files into dicts for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "F485A_Y486A_ys_e, F485A_Y486A_xs_e, Nieduszynski_df_e,F485A_Y486A_peaks_e = get_smooth_reads(bed_file_name='EdU_supplementary_data/EdU_F485A_Y486A_Pd03_rep1.txt',smoothing_window_size=5000)\n",
    "WT_ys_e, WT_xs_e, Nieduszynski_df_e, WT_peaks_e = get_smooth_reads(bed_file_name='EdU_supplementary_data/EdU_WT_rep2.txt',smoothing_window_size=5000)\n",
    "F485I_ys_e, F485I_xs_e, Nieduszynski_df_e,F485I_peaks_e = get_smooth_reads(bed_file_name='EdU_supplementary_data/EdU_F485I_rep1_pd02.txt',smoothing_window_size=5000)\n",
    "F485I_Y486Q_ys_e, F485I_Y486Q_xs_e, Nieduszynski_df_e,F485I_Y486Q_peaks_e = get_smooth_reads(bed_file_name='EdU_supplementary_data/EdU_F485I_Y486Q_rep2_pd15.txt',smoothing_window_size=5000)\n",
    "N489W_ys_e, N489W_xs_e, Nieduszynski_df_e,N489W_peaks_e = get_smooth_reads(bed_file_name='EdU_supplementary_data/EdU_N489W_rep1_pd06.txt',smoothing_window_size=5000)\n",
    "R478A_ys_e, R478A_xs_e, Nieduszynski_df_e,R478A_peaks_e = get_smooth_reads(bed_file_name='EdU_supplementary_data/EdU_R478A_Pd11_rep1.txt',smoothing_window_size=5000)\n",
    "R478K_ys_e, R478K_xs_e, Nieduszynski_df_e,R478K_peaks_e = get_smooth_reads(bed_file_name='EdU_supplementary_data/EdU_R487K_rep1_pd12.txt',smoothing_window_size=5000)\n",
    "Y486Q_ys_e, Y486Q_xs_e, Nieduszynski_df_e,Y486Q_peaks_e = get_smooth_reads(bed_file_name='EdU_supplementary_data/EdU_Y486Q_rep1_pd08.txt',smoothing_window_size=5000)\n",
    "F485Y_Y486F_ys_e, F485Y_Y486F_xs_e, Nieduszynski_df_e, F485Y_Y486F_peaks_e = get_smooth_reads(bed_file_name='EdU_supplementary_data/EdU_F485Y_Y486F_rep1_pd04.txt',smoothing_window_size=5000)\n",
    "N489A_ys_e, N489A_xs_e, Nieduszynski_df_e, N489A_peaks_e = get_smooth_reads(bed_file_name='EdU_supplementary_data/EdU_N489A_Pd05_rep1.txt',smoothing_window_size=5000)\n",
    "mrc1_ys_e, mrc1_xs_e, Nieduszynski_df_e, mrc1_peaks_e = get_smooth_reads(bed_file_name='EdU_supplementary_data/delta_mrc1_WT_rep2_LID_300522.txt',smoothing_window_size=5000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Stacked EdU profiles (replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n",
      "(0, '$\\\\Delta$mrc1')\n",
      "(1, 'OriDB Confirmed ARS')\n",
      "(2, '$\\\\mathregular{Orc4}^{\\\\mathregular{WT}}$')\n",
      "(3, '$\\\\mathregular{orc4}^{\\\\mathregular{F485Y,Y486F}}$')\n",
      "(4, '$\\\\mathregular{orc4}^{\\\\mathregular{Y486Q}}$')\n",
      "(5, '$\\\\mathregular{orc4}^{\\\\mathregular{R478K}}$')\n",
      "(6, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I}}$')\n",
      "(7, '$\\\\mathregular{orc4}^{\\\\mathregular{F485A,Y486A}}$')\n",
      "(8, '$\\\\mathregular{orc4}^{\\\\mathregular{N489W}}$')\n",
      "(9, '$\\\\mathregular{orc4}^{\\\\mathregular{F485I,Y486Q}}$')\n",
      "(10, '$\\\\mathregular{orc4}^{\\\\mathregular{R478A}}$')\n",
      "(11, '$\\\\mathregular{orc4}^{\\\\mathregular{N489A}}$')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_x_data = [\n",
    "        (mrc1_ys_e,mrc1_xs_e),\n",
    "        (WT_ys_e, WT_xs_e),\n",
    "        (WT_ys_e, WT_xs_e),\n",
    "        (F485Y_Y486F_ys_e, F485Y_Y486F_xs_e),\n",
    "        (Y486Q_ys_e, Y486Q_xs_e),\n",
    "        (R478K_ys_e, R478K_xs_e),\n",
    "        (F485I_ys_e, F485I_xs_e),\n",
    "        (F485A_Y486A_ys_e,F485A_Y486A_xs_e),\n",
    "        (N489W_ys_e, N489W_xs_e),\n",
    "        (F485I_Y486Q_ys_e, F485I_Y486Q_xs_e),\n",
    "        (R478A_ys_e, R478A_xs_e),\n",
    "        (N489A_ys_e, N489A_xs_e),\n",
    "        ]\n",
    "#mrc1_ys_e, mrc1_xs_e, Nieduszynski_df_e, mrc1_peaks_e\n",
    "\n",
    "y_labels = [r'$\\Delta$mrc1','OriDB Confirmed ARS'\n",
    "            ,r'$\\mathregular{Orc4}^{\\mathregular{WT}}$'\n",
    "            ,r'$\\mathregular{orc4}^{\\mathregular{F485Y,Y486F}}$',\n",
    "            r'$\\mathregular{orc4}^{\\mathregular{Y486Q}}$',\n",
    "            r'$\\mathregular{orc4}^{\\mathregular{R478K}}$',\n",
    "            r'$\\mathregular{orc4}^{\\mathregular{F485I}}$',\n",
    "            r'$\\mathregular{orc4}^{\\mathregular{F485A,Y486A}}$',\n",
    "            r'$\\mathregular{orc4}^{\\mathregular{N489W}}$',\n",
    "            r'$\\mathregular{orc4}^{\\mathregular{F485I,Y486Q}}$',\n",
    "            r'$\\mathregular{orc4}^{\\mathregular{R478A}}$',\n",
    "            r'$\\mathregular{orc4}^{\\mathregular{N489A}}$']\n",
    "# y_labels = ['WT','F485I','N489A','F485A_Y486A','F485I_Y486Q','mrc1D']\n",
    "\n",
    "# randomly generated\n",
    "colors_list = [ \n",
    "                [1.0, 0.0, 0.0], # MRC1\n",
    "                [1.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 1.0], # WT\n",
    "                [0.61252607, 0.89187607, 0.02175532],    # F485Y,Y486F\n",
    "                [0.45630455, 0.82612284, 0.25137413],    # Y486Q\n",
    "                [0.61252607, 0.02175532, 0.89187607],    # R478K\n",
    "                [0.74880388, 0.49850701, 0.22479665],    # F485I\n",
    "                [0.51313824, 0.65039718, 0.60103895],    # F485A,Y486A\n",
    "\n",
    "                [0.08833981, 0.68535982, 0.95339335],    # N489W\n",
    "                [0.65039718, 0.51313824, 0.60103895],    # F485I,Y486Q\n",
    "                \n",
    "                [0.14217005, 0.37334076, 0.67413362],    # R478A\n",
    "                [0.49850701, 0.22479665, 0.74880388],    # N489A\n",
    "]\n",
    "\n",
    "\n",
    "for current_chromosome in chrX_list:\n",
    "#for current_chromosome in ['chr16']:\n",
    "\n",
    "    chromosome_to_plot = current_chromosome    \n",
    "    np.random.seed(10)\n",
    "    \n",
    "    #chromosome_to_plot='chr4'\n",
    "    ars_names_list_conrad = Nieduszynski_df_e.loc[Nieduszynski_df_e['chromosome'] == chromosome_to_plot]['name'].tolist()\n",
    "    ars_position_list_conrad = Nieduszynski_df_e.loc[Nieduszynski_df_e['chromosome'] == chromosome_to_plot]['position'].tolist()\n",
    "\n",
    "\n",
    "    f1, axarr_e = plt.subplots(len(y_labels), sharex=True,figsize=(30,20))\n",
    "    #f, axarr = plt.subplots(len(y_labels), sharex=True,figsize=(4.72441,4.72441))\n",
    "    axarr_e[0].set_title('EDU EXP2 - Replication profile: '+chromosome_to_plot,fontsize=25)\n",
    "\n",
    "    plot_index = 0\n",
    "    for y_data,x_data in y_x_data:\n",
    "        \n",
    "        print(plot_index,y_labels[plot_index])\n",
    "        if plot_index==1:    \n",
    "            for ars_name_index in range(len(ars_names_list_conrad)):\n",
    "            # draws dashed oridb line\n",
    "                axarr_e[plot_index].axvline(x=ars_position_list_conrad[ars_name_index]/kb,linewidth=3,linestyle='solid',color='black',clip_on=False,ymin=0.25,ymax=0.75,zorder=1)    \n",
    "                axarr_e[plot_index].set_ylabel(y_labels[plot_index],fontsize=30, rotation=0, labelpad=0,horizontalalignment='right')\n",
    "                #axarr_e[plot_index].yaxis.set_label_coords(-0.055, 0.35)\n",
    "        else:\n",
    "\n",
    "\n",
    "            axarr_e[plot_index].plot(x_data[chromosome_to_plot], y_data[chromosome_to_plot]/percentile_across_genome(y_data),linewidth=5,color=colors_list[plot_index])\n",
    "            axarr_e[plot_index].set_ylabel(y_labels[plot_index],fontsize=35, rotation=0, labelpad=0,horizontalalignment='right')\n",
    "            #axarr_e[plot_index].tick_params(axis='y', which='major', labelsize=30)\n",
    "            axarr_e[plot_index].fill_between(x_data[chromosome_to_plot], y_data[chromosome_to_plot]/percentile_across_genome(y_data),color=colors_list[plot_index])\n",
    "            if current_chromosome=='chr12':\n",
    "                if plot_index==8:\n",
    "                    axarr_e[plot_index].set_ylim(0,0.75)\n",
    "                elif plot_index==0:\n",
    "                    axarr_e[plot_index].set_ylim(0,0.5)\n",
    "                else:\n",
    "                    axarr_e[plot_index].set_ylim(0,0.1)\n",
    "\n",
    "        axarr_e[plot_index].yaxis.set_label_coords(0.03, 0.15)\n",
    "        \n",
    "        # remove spines\n",
    "        axarr_e[plot_index].spines['right'].set_visible(False)\n",
    "        axarr_e[plot_index].spines['top'].set_visible(False)\n",
    "        axarr_e[plot_index].spines['bottom'].set_visible(False)\n",
    "        axarr_e[plot_index].spines['left'].set_visible(False)\n",
    "\n",
    "        # remove y-ticks\n",
    "        axarr_e[plot_index].set_yticks([])\n",
    "\n",
    "        if plot_index==0:\n",
    "                axarr_e[0].set_title('EdU replicate profiles: '+chromosome_to_plot,fontsize=30)\n",
    "        \n",
    "        plot_index +=1\n",
    "\n",
    "    height_where_text_is_drawn = 0.7 # chr 4\n",
    "\n",
    "    max_height_of_vlines = 12.25\n",
    "    \n",
    "    # set label size of x-axis for the bottom-of-stack plot\n",
    "    axarr_e[plot_index-1].tick_params(axis='x', which='major', labelsize=30)  \n",
    "    axarr_e[plot_index-1].set_xlabel(chromosome_to_plot + ' position (in kb)', fontsize=30)\n",
    "    f1.subplots_adjust(hspace=0.25)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig('EdU_replicates_profiles/Figure_EdU_replicates_supplement_'+current_chromosome+'.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
